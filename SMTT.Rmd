---
title: "Sentiment Analysis"
resource_files:
- negative-words.txt
- positive-words.txt
output:
  flexdashboard::flex_dashboard:
    orientation: rows
    runtime: shiny
    vertical_layout: fill
---

```{r setup, include=FALSE}
#install.packages("twitteR")
#install.packages("ROAuth")
#install.packages("tm")
#install.packages("corpus")
library(flexdashboard)
library(knitr)
library(DT)
library(twitteR)
library(ROAuth)
library(plyr)
library(dplyr)
library(stringr)
library(reshape)
library(plotly)
library(tm)
library(corpus)
library(wordcloud)
#library(keyring)
library(syuzhet)
```


```{r global, include=FALSE}

consumer_key <- "PzaYQoExZn2dtCUg02T14iwmI"
consumer_secret <- "FWSwNSFh74ytPrLscz36vIdARHlKZKddz2sJWqao03Rn8jfGne"
access_token <- "954792333941161984-w1pLFTxuNBB7xMdjf6PHmPPqkp00hIE"
access_secret <- "lQWgIyj4qJZrXaBa7uAKmMvNJhewp6zggdsDgwTnZGP9G"

setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
pos.words <- scan('positive-words.txt', what = 'character', comment.char = ';')

neg.words <- scan('negative-words.txt', what = 'character', comment.char = ';')

```


```{r}

## data processing
chartdata <- reactive({
  
  withProgress({
        setProgress(message = "Getting Tweets...")
## getting data
situation <- searchTwitter(as.character(input$searchedword), n=input$no_of_tweets)


return(situation)

    })
  })

inputdata <- reactive({
  ip1 <- input$searchedword
  ip2 <- input$wordcount
  return(list(ip1,ip2))
})


```


Sidebar {.sidebar}
=====================================

```{r}
textInput("searchedword", "Enter your Text here", "Environment")

sliderInput("no_of_tweets", "How many Tweets??",
                  min = 0, max = 10000,
                  value = 100)

sliderInput("wordcount", "How many Words??",
                  min = 0, max = 10000,
                  value = 500)


textInput("loc", "Enter Location Id", "2295424")

```


Main Page
======================================


### Sentiment Scores

```{r}
renderPlot({
  withProgress(message = "Loading Chart...", {
  situation <- chartdata()
  situationDF <- twListToDF(situation)

##data cleaning
situationDF$text <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+","",situationDF$text)

situationDF$text <- sapply(situationDF$text, function(row) iconv(row, "latin1","ASCII",sub=""))

sentence <- situationDF$text
sentence = gsub('[[:punct:]]','',sentence)
    sentence = gsub('[[:cntrl:]]','',sentence)
    sentence = gsub('\\d+','',sentence) #removes decimal no.
    sentence = gsub('\n','',sentence) #removes new lines
    
    sentence= tolower(sentence)
    s <- get_nrc_sentiment(sentence)
    
    barplot(colSums(s),
        las = 2,
        col = rainbow(10),
        ylab = 'Score',
        main = 'Sentiments Inside')

  })
})
```



Word Cloud
================================

### Word Cloud


```{r}
renderPlot({
  withProgress(message = "Loading Chart...", {
  situation <- chartdata()
  ##data preparation for word cloud
  situation = sapply(situation, function(x) x$getText())  #sapply returns a vector
situation<- do.call("rbind",lapply(situation, as.data.frame)) # lapply returns a list

situation <- sapply(situation, function(row) iconv(row, "latin1","ASCII",sub=""))
situation_corpus <- Corpus(VectorSource(situation)) 
situation_clean <- tm_map(situation_corpus, removePunctuation)
situation_clean <- tm_map(situation_clean, removeWords, stopwords("english"))
situation_clean <- tm_map(situation_clean, removeNumbers)
situation_clean <- tm_map(situation_clean, stripWhitespace)
situation_clean <- tm_map(situation_clean, content_transformer(tolower))
situation_clean <- tm_map(situation_clean, removeWords,c(tolower(inputdata()[1]),'https'))
  
  wordcloud(situation_clean,random.order= F,max.words=inputdata()[2], col = rainbow(50),scale=c(2,1))

  })
})
```


Pie Chart
==========================


### Pie Chart

```{r}
labels <- c("Positive","Negative")
mycolors <- c("green","red")

renderPlotly({
  withProgress(message = "Loading Chart...", {
  situation <- chartdata()
  situationDF <- twListToDF(situation)

##data cleaning
situationDF$text <- gsub("(f|ht)tp(s?)://(.*)[.][a-z]+","",situationDF$text)

situationDF$text <- sapply(situationDF$text, function(row) iconv(row, "latin1","ASCII",sub=""))

sample <- situationDF$text

score.sentiment = function(sentences, pos.words, neg.words, .progress='none')
  
{
  
  list=lapply(sentences,function(sentence, pos.words, neg.words)
  {
    sentence = gsub('[[:punct:]]','',sentence)
    sentence = gsub('[[:cntrl:]]','',sentence)
    sentence = gsub('\\d+','',sentence) #removes decimal no.
    sentence = gsub('\n','',sentence) #removes new lines
    
    sentence= tolower(sentence)
    word.list= str_split(sentence, '\\s+')
    words = unlist(word.list)        #changes a list to character vector
    pos.matches = match(words, pos.words)
    neg.matches = match(words, neg.words)
    pos.matches = !is.na(pos.matches)
    neg.matches = !is.na(neg.matches)
    pp = sum(pos.matches)
    nn = sum(neg.matches) 
    score = sum(pos.matches) - sum(neg.matches)
    list1 = c(score, pp, nn)
    return (list1)
    
  }, pos.words, neg.words)
  score_new = lapply(list,'[[', 1) 
  pp1 = lapply(list,'[[', 2)
  nn1 = lapply(list,'[[', 3)
  
  scores.df = data.frame(score = score_new, text=sentences)
  positive.df = data.frame(Positive= pp1, text=sentences)
  negative.df = data.frame(Negative= nn1, text=sentences)
  
  list_df = list(scores.df,positive.df,negative.df)
  return(list_df)
}


#cleans the tweets and returns merged data frame
result = score.sentiment(sample, pos.words, neg.words)

#create a copy of result dataframe
test1 = result [[1]]
test2 = result [[2]]
test3 = result [[3]]

test1$text = NULL
test2$text = NULL
test3$text = NULL

q1= test1[1,]
q2= test2[1,]
q3= test3[1,]

qq1=melt(q1, , var='Score') #merge all results
qq2=melt(q2, , var='Positive')
qq3=melt(q3, , var='Negative')

qq1['Score']= NULL
qq2['Positive']= NULL
qq3['Negative']= NULL

table1 = data.frame(Text=result[[1]]$text, Score=qq1)
table2 = data.frame(Text=result[[2]]$text, Score=qq2)
table3 = data.frame(Text=result[[3]]$text, Score=qq3)

#merge tables
table_final = data.frame(Text = table1$Text, Score = table1$value, Positive = table2$value, Negative = table3$value)

#Positive Percentage
table_final$Pospercent = table_final$Positive/(table_final$Positive+table_final$Negative)

#Negative Percentage
table_final$Negpercent = table_final$Negative/(table_final$Positive+table_final$Negative)

#replacing Nan with zero

table_final$Pospercent[is.nan(table_final$Pospercent)] <-0
table_final$Negpercent[is.nan(table_final$Negpercent)] <-0

#values =~as.numeric(unlist(chartdata()[1])),
##data for pie chart
piedata <- c(sum(table_final$Positive),sum(table_final$Negative))
  plot_ly(labels =~labels,
          values =~piedata,
          marker = list(colors = mycolors)) %>%
    add_pie(hole = 0.3)
  })
})
```

Top Trends
============================


Column
------------------------------------------


### Top Trending

```{r}
trending_data <- reactive({
  trends <- getTrends(input$loc)
  toptrends <- top_n(as.data.frame(trends$name),20)
  names(toptrends)[1] <- " "
  toptrends
    })


renderPrint({
  trending_data()
    })
```

Refer Location ID
===============================


### Location & Where on Earth ID

```{r}
location <- availableTrendLocations()
```


```{r}
datatable(location,
          caption = "Location & Where on Earth ID",
          rownames = T,
          filter = "top",
          options = list(pageLength = 25))
```


About Report
========================================

Created by: Vignesh EA

Confidential: Nothing like that!